[06/11 13:17:11][INFO] visual_prompt:   95: Rank of current process: 0. World size: 4
[06/11 13:17:11][INFO] visual_prompt:   97: Environment info:
-------------------  ---------------------------------------------------
Python               3.8.13 (default, Mar 28 2022, 11:38:47) [GCC 7.5.0]
ENV_MODULE           <not set>
PyTorch              1.13.0+cu117
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3,5,6,7
GPU 0,1,2,3          Tesla V100-SXM2-32GB
Pillow               9.3.0
cv2                  4.7.0
-------------------  ---------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[06/11 13:17:11][INFO] visual_prompt:   99: Command line arguments: None
[06/11 13:17:11][INFO] visual_prompt:  108: Training with config:
[06/11 13:17:11][INFO] visual_prompt:  109: {'CUDNN_BENCHMARK': False,
 'DATA': {'AUGMENTED': True,
          'BATCH_SIZE': 256,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': '../../imagenet1k',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MODE': 'classification',
          'MULTILABEL': False,
          'NAME': 'imagenet',
          'NO_TEST': True,
          'NUMBER_CLASSES': 1000,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True,
          'PREDICT_ROTATION': False,
          'TRANSFORM': 'rotation'},
 'DBG': True,
 'DIST_BACKEND': 'nccl',
 'DIST_INIT_FILE': '',
 'DIST_INIT_PATH': 'tcp://localhost:10001',
 'GPU_ID': None,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'checkpoints',
           'MULTIPLE_HEAD': True,
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': False,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_INVAR_TYPES': 31,
                      'NUM_TOKENS': 1550,
                      'NUM_TOKENS_PER_TYPE': 50,
                      'PROJECT': -1,
                      'PROMPT_PATH': '',
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': True,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 4,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'output_kl/imagenet/sup_vitb16_imagenet21k/lr1.0_wd0.001/run1',
 'RANK': 0,
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 1.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'kl',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.001,
            'WEIGHT_DECAY_BIAS': 0},
 'WORLD_SIZE': 4}
[06/11 13:17:15][INFO] visual_prompt:   52: Classification Model:
ViT(
  (enc): PromptedVisionTransformer(
    (transformer): PromptedTransformer(
      (embeddings): Embeddings(
        (patch_embeddings): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): Encoder(
        (layer): ModuleList(
          (0): Block(
            (attention_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (ffn_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (ffn): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (attn): Attention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (out): Linear(in_features=768, out_features=768, bias=True)
              (attn_dropout): Dropout(p=0.0, inplace=False)
              (proj_dropout): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
          )
          (1): Block(
            (attention_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (ffn_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (ffn): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (attn): Attention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (out): Linear(in_features=768, out_features=768, bias=True)
              (attn_dropout): Dropout(p=0.0, inplace=False)
              (proj_dropout): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
          )
          (2): Block(
            (attention_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (ffn_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (ffn): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (attn): Attention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (out): Linear(in_features=768, out_features=768, bias=True)
              (attn_dropout): Dropout(p=0.0, inplace=False)
              (proj_dropout): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
          )
          (3): Block(
            (attention_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (ffn_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (ffn): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (attn): Attention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (out): Linear(in_features=768, out_features=768, bias=True)
              (attn_dropout): Dropout(p=0.0, inplace=False)
              (proj_dropout): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
          )
          (4): Block(
            (attention_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (ffn_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (ffn): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (attn): Attention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (out): Linear(in_features=768, out_features=768, bias=True)
              (attn_dropout): Dropout(p=0.0, inplace=False)
              (proj_dropout): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
          )
          (5): Block(
            (attention_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (ffn_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (ffn): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (attn): Attention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (out): Linear(in_features=768, out_features=768, bias=True)
              (attn_dropout): Dropout(p=0.0, inplace=False)
              (proj_dropout): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
          )
          (6): Block(
            (attention_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (ffn_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (ffn): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (attn): Attention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (out): Linear(in_features=768, out_features=768, bias=True)
              (attn_dropout): Dropout(p=0.0, inplace=False)
              (proj_dropout): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
          )
          (7): Block(
            (attention_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (ffn_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (ffn): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (attn): Attention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (out): Linear(in_features=768, out_features=768, bias=True)
              (attn_dropout): Dropout(p=0.0, inplace=False)
              (proj_dropout): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
          )
          (8): Block(
            (attention_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (ffn_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (ffn): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (attn): Attention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (out): Linear(in_features=768, out_features=768, bias=True)
              (attn_dropout): Dropout(p=0.0, inplace=False)
              (proj_dropout): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
          )
          (9): Block(
            (attention_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (ffn_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (ffn): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (attn): Attention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (out): Linear(in_features=768, out_features=768, bias=True)
              (attn_dropout): Dropout(p=0.0, inplace=False)
              (proj_dropout): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
          )
          (10): Block(
            (attention_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (ffn_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (ffn): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (attn): Attention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (out): Linear(in_features=768, out_features=768, bias=True)
              (attn_dropout): Dropout(p=0.0, inplace=False)
              (proj_dropout): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
          )
          (11): Block(
            (attention_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (ffn_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (ffn): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (attn): Attention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (out): Linear(in_features=768, out_features=768, bias=True)
              (attn_dropout): Dropout(p=0.0, inplace=False)
              (proj_dropout): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
          )
        )
        (encoder_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      )
      (prompt_dropout): Dropout(p=0.1, inplace=False)
      (prompt_proj): Identity()
    )
    (head): Identity()
  )
  (head): ModuleList(
    (0): MLP(
      (projection): Sequential()
      (last_layer): Linear(in_features=768, out_features=1000, bias=True)
    )
    (1): MLP(
      (projection): Sequential()
      (last_layer): Linear(in_features=768, out_features=1000, bias=True)
    )
    (2): MLP(
      (projection): Sequential()
      (last_layer): Linear(in_features=768, out_features=1000, bias=True)
    )
    (3): MLP(
      (projection): Sequential()
      (last_layer): Linear(in_features=768, out_features=1000, bias=True)
    )
    (4): MLP(
      (projection): Sequential()
      (last_layer): Linear(in_features=768, out_features=1000, bias=True)
    )
    (5): MLP(
      (projection): Sequential()
      (last_layer): Linear(in_features=768, out_features=1000, bias=True)
    )
    (6): MLP(
      (projection): Sequential()
      (last_layer): Linear(in_features=768, out_features=1000, bias=True)
    )
    (7): MLP(
      (projection): Sequential()
      (last_layer): Linear(in_features=768, out_features=1000, bias=True)
    )
    (8): MLP(
      (projection): Sequential()
      (last_layer): Linear(in_features=768, out_features=1000, bias=True)
    )
    (9): MLP(
      (projection): Sequential()
      (last_layer): Linear(in_features=768, out_features=1000, bias=True)
    )
    (10): MLP(
      (projection): Sequential()
      (last_layer): Linear(in_features=768, out_features=1000, bias=True)
    )
    (11): MLP(
      (projection): Sequential()
      (last_layer): Linear(in_features=768, out_features=1000, bias=True)
    )
    (12): MLP(
      (projection): Sequential()
      (last_layer): Linear(in_features=768, out_features=1000, bias=True)
    )
    (13): MLP(
      (projection): Sequential()
      (last_layer): Linear(in_features=768, out_features=1000, bias=True)
    )
    (14): MLP(
      (projection): Sequential()
      (last_layer): Linear(in_features=768, out_features=1000, bias=True)
    )
    (15): MLP(
      (projection): Sequential()
      (last_layer): Linear(in_features=768, out_features=1000, bias=True)
    )
    (16): MLP(
      (projection): Sequential()
      (last_layer): Linear(in_features=768, out_features=1000, bias=True)
    )
    (17): MLP(
      (projection): Sequential()
      (last_layer): Linear(in_features=768, out_features=1000, bias=True)
    )
    (18): MLP(
      (projection): Sequential()
      (last_layer): Linear(in_features=768, out_features=1000, bias=True)
    )
    (19): MLP(
      (projection): Sequential()
      (last_layer): Linear(in_features=768, out_features=1000, bias=True)
    )
    (20): MLP(
      (projection): Sequential()
      (last_layer): Linear(in_features=768, out_features=1000, bias=True)
    )
    (21): MLP(
      (projection): Sequential()
      (last_layer): Linear(in_features=768, out_features=1000, bias=True)
    )
    (22): MLP(
      (projection): Sequential()
      (last_layer): Linear(in_features=768, out_features=1000, bias=True)
    )
    (23): MLP(
      (projection): Sequential()
      (last_layer): Linear(in_features=768, out_features=1000, bias=True)
    )
    (24): MLP(
      (projection): Sequential()
      (last_layer): Linear(in_features=768, out_features=1000, bias=True)
    )
    (25): MLP(
      (projection): Sequential()
      (last_layer): Linear(in_features=768, out_features=1000, bias=True)
    )
    (26): MLP(
      (projection): Sequential()
      (last_layer): Linear(in_features=768, out_features=1000, bias=True)
    )
    (27): MLP(
      (projection): Sequential()
      (last_layer): Linear(in_features=768, out_features=1000, bias=True)
    )
    (28): MLP(
      (projection): Sequential()
      (last_layer): Linear(in_features=768, out_features=1000, bias=True)
    )
    (29): MLP(
      (projection): Sequential()
      (last_layer): Linear(in_features=768, out_features=1000, bias=True)
    )
    (30): MLP(
      (projection): Sequential()
      (last_layer): Linear(in_features=768, out_features=1000, bias=True)
    )
  )
)
[06/11 13:17:15][INFO] visual_prompt:   56: Total Parameters: 110828056	 Gradient Parameters: 25029400
[06/11 13:17:15][INFO] visual_prompt:   58: tuned percent:22.584
[06/11 13:17:15][INFO] visual_prompt:   44: Device used for model: 0
[06/11 13:17:15][INFO] visual_prompt:   72: Loading training data (final training data for vtab)...
[06/11 13:17:15][INFO] visual_prompt:   49: Constructing imagenet dataset train...
[06/11 13:17:18][INFO] visual_prompt:  110: Number of images: 1281167
[06/11 13:17:18][INFO] visual_prompt:  111: Number of classes: 1000
[06/11 13:17:18][INFO] visual_prompt:   78: Loading validation data...
[06/11 13:17:18][INFO] visual_prompt:   49: Constructing imagenet dataset val...
[06/11 13:17:18][INFO] visual_prompt:  110: Number of images: 50000
[06/11 13:17:18][INFO] visual_prompt:  111: Number of classes: 1000
[06/11 13:17:18][INFO] visual_prompt:   81: Loading test data...
[06/11 13:17:18][INFO] visual_prompt:   83: ...no test data is constructed
[06/11 13:17:18][INFO] visual_prompt:  111: Constructing models...
[06/11 13:17:18][INFO] visual_prompt:  114: Setting up Evalutator...
[06/11 13:17:18][INFO] visual_prompt:  116: Setting up Trainer...
[06/11 13:17:18][INFO] visual_prompt:   47: 	Setting up the optimizer...
